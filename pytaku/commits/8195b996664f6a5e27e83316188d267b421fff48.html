<!DOCTYPE html>
<html lang="en" style="font-family: monospace;"><head><title>[8195b99666] concurrent &amp; crash-proof search | pytaku | Boast</title><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"></head><body><strong><a href="../../">Repos</a> / <a href="../">pytaku</a> / 8195b99666</strong><hr><pre>commit 8195b996664f6a5e27e83316188d267b421fff48
Author: Bùi Thành Nhân &lt;hi@imnhan.com&gt;
Date:   Sat Aug 29 16:24:28 2020 +0700

    concurrent &amp; crash-proof search
    
    I still dislike the catch-all though, so gotta fix that once I&#39;ve sorted
    out user-facing error reporting.
    
    Also increased mangasee search cache lifespan.

diff --git a/pyproject.toml b/pyproject.toml
index f71d4ea..e6764bf 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -1,6 +1,6 @@
 [tool.poetry]
 name = &quot;pytaku&quot;
-version = &quot;0.3.10&quot;
+version = &quot;0.3.11&quot;
 description = &quot;Self-hostable web-based manga reader&quot;
 authors = [&quot;Bùi Thành Nhân &lt;hi@imnhan.com&gt;&quot;]
 license = &quot;AGPL-3.0-only&quot;
diff --git a/src/mangoapi/base_site.py b/src/mangoapi/base_site.py
index 65990c1..6f1884d 100644
--- a/src/mangoapi/base_site.py
+++ b/src/mangoapi/base_site.py
@@ -48,6 +48,10 @@ def login(self, username, password):
 
     def _http_request(self, method, *args, **kwargs):
         request_func = getattr(self._session, method)
+
+        if &quot;timeout&quot; not in kwargs:
+            kwargs[&quot;timeout&quot;] = 5
+
         resp = request_func(*args, **kwargs)
 
         if 500 &lt;= resp.status_code &lt;= 599:
diff --git a/src/mangoapi/mangasee.py b/src/mangoapi/mangasee.py
index 8ffa305..3b07bf9 100644
--- a/src/mangoapi/mangasee.py
+++ b/src/mangoapi/mangasee.py
@@ -25,7 +25,7 @@ def __init__(self, keyval_store=None):
         self.keyval_store = keyval_store
 
     def get_title(self, title_id):
-        resp = self.http_get(f&quot;https://mangasee123.com/manga/{title_id}&quot;, timeout=3)
+        resp = self.http_get(f&quot;https://mangasee123.com/manga/{title_id}&quot;)
         html = resp.text
         name = regexes[&quot;title_name&quot;].search(html).group(1).strip()
         desc = regexes[&quot;title_desc&quot;].search(html).group(1).strip()
@@ -102,7 +102,7 @@ def search_title(self, query):
             titles = None
             if self.keyval_store:
                 titles = json.loads(
-                    self.keyval_store.get(&quot;mangasee_titles&quot;, &quot;null&quot;, since=&quot;-1 day&quot;)
+                    self.keyval_store.get(&quot;mangasee_titles&quot;, &quot;null&quot;, since=&quot;-20 day&quot;)
                 )
             if not titles:
                 print(&quot;Fetching mangasee title list...&quot;, end=&quot;&quot;)
diff --git a/src/pytaku/source_sites.py b/src/pytaku/source_sites.py
index ebfd3ba..62f0438 100644
--- a/src/pytaku/source_sites.py
+++ b/src/pytaku/source_sites.py
@@ -1,3 +1,6 @@
+import traceback
+from concurrent.futures import ThreadPoolExecutor, as_completed
+
 from mangoapi import get_site_class
 
 from .conf import config
@@ -55,7 +58,27 @@ def search_title_all_sites(query):
     Returns dict in the form of {site_name: List[Title]}
     I should really look into proper type annotations huh.
     &quot;&quot;&quot;
-    return {
-        site_name: search_title(site_name, query)
-        for site_name in (&quot;mangasee&quot;, &quot;mangadex&quot;)
-    }
+    site_names = (&quot;mangasee&quot;, &quot;mangadex&quot;)
+    results = {}
+
+    def safe_search(site_name, query):
+        try:
+            return search_title(site_name, query)
+        except Exception:
+            print(f&quot;{site_name}&#39;s search function shat the bed:&quot;)
+            traceback.print_exc()
+            return []
+
+    # Concurrently search from multiple sites.
+    # Obviously network I/O bound so a thread pool is appropriate enough.
+    with ThreadPoolExecutor(max_workers=5) as executor:
+        future_to_site_name = {
+            executor.submit(safe_search, site_name, query): site_name
+            for site_name in site_names
+        }
+        for future in as_completed(future_to_site_name):
+            site_results = future.result()
+            site_name = future_to_site_name[future]
+            results[site_name] = site_results
+
+    return results
</pre></body></html>